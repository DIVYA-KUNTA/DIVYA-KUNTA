{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58ebb0ec-847a-4f50-a9fd-6a272e463f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3daa42ab-16af-4ad4-a807-cefc27aa0bd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment 1: Streamlined Data Ingestion\n",
    "\n",
    "Now that we have a good idea of what we want the data prep on transactions looks like,\n",
    "let's push that to the read_csv function. \n",
    "\n",
    "Keep an eye on the memory usage before and after. \n",
    "\n",
    "* Change the column names to 'Date', 'Store_Number', and 'Transaction_Count'.\n",
    "* Skip the first row of data.\n",
    "* Convert columns to the appropriate datatypes. \n",
    "\n",
    "Then create the columns we created in the assign assignment in Section 3, by chaining assign with read_csv. \n",
    "\n",
    "Some starter code has been provided for you below. Because the dataframe object returned by read_csv doesn't have a name, we need to use a lambda function to refer to the dataframe.\n",
    "\n",
    "`transactions.assign(\n",
    "    target_pct=transactions[\"transactions\"] / 2500,\n",
    "    met_target=(transactions[\"transactions\"] / 2500) >= 1,\n",
    "    bonus_payable=((transactions[\"transactions\"] / 2500) >= 1) * 100,\n",
    "    month=transactions[\"date\"].dt.month,\n",
    "    day_of_week=transactions[\"date\"].dt.dayofweek,\n",
    ")`\n",
    "\n",
    "The first one should look like:\n",
    "\n",
    "`target_pct = lambda x: (x[\"Transaction_Count\"] / 2500)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78269e5a-80bb-4284-b136-5e8e9d82b153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"../retail/transactions.csv\").info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96b3827a-8c47-44d4-8e35-58b7858eebf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions = pd.read_csv(\n",
    "    \"../retail/transactions.csv\",                                          \n",
    "    header=0,                                                              # Suppress header to allow custom names\n",
    "    names=[\"Date\", \"Store_Number\", \"Transaction_Count\"],                   # Specify new column names\n",
    "    skiprows=[0],                                                          # Skip the first row of data\n",
    "    parse_dates=[\"Date\"],                                                  # parse date column\n",
    "    dtype={\"Store_Number\": \"Int8\", \"Transaction_Count\": \"Int16\"}).assign(  # Downcast two integer columns\n",
    "    target_pct = lambda x: (x[\"Transaction_Count\"] / 2500),\n",
    "    met_target = lambda x: (x[\"Transaction_Count\"] / 2500 >= 1),\n",
    "    bonus_payable = lambda x: (x[\"Transaction_Count\"] / 2500 >= 1 * 100),\n",
    "    month = lambda x: x[\"Date\"].dt.month,\n",
    "    day_of_week = lambda x: x[\"Date\"].dt.dayofweek,\n",
    ").astype({                                                                 # Cast new columns to correct dtypes.\n",
    "    \"target_pct\": \"Float32\",                                               # Note this could also be done in assign\n",
    "    \"month\": \"Int8\",                                                      \n",
    "    \"day_of_week\": \"Int8\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f859cec-262d-42f9-9513-0f330cdd8c92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Df is significantly reduced in size! \n",
    "\n",
    "transactions.info(memory_usage=\"deep\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "372a40ab-7911-4a4f-ac9b-a3ab8d8268be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment 2: Write to Excel Sheets\n",
    "\n",
    "Write the data in the transactions dataframe you created above into an Excel workbook.\n",
    "\n",
    "Write out a separate sheet for each year of the data.\n",
    "\n",
    "If you prefer, you can write each year of data to a separate csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e9d11ab-60c5-4ce9-b02c-2acbed776991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "355f89c1-82a8-4635-b527-188a7001fb9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32b9398b-c34f-4236-ab50-b0e24dbd460e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Open ExcelWriter to write multiple sheets\n",
    "\n",
    "with pd.ExcelWriter(\"DataForChandler.xlsx\") as writer:\n",
    "    for year in range(2013, 2018):                 # Specify years to filter by for each sheet and loop through them\n",
    "       (transactions\n",
    "        .loc[transactions[\"Date\"].dt.year == year] # Filter DF to year in current iteration of loop\n",
    "        .to_excel(writer, sheet_name=str(year)))   # Write each year's DF to sheet named for that year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67dee569-fad6-4104-b659-7a36bc5b0cb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for year in range(2013, 2018):                     # Specify years to filter by for each sheet and loop through them\n",
    "    (transactions\n",
    "     .loc[transactions[\"Date\"].dt.year == year]    # Filter DF to year in current iteration of loop\n",
    "     .to_csv(f\"transactions_{year}.csv\")           # Write each year's DF to sheet named for that year\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cf2c55d-0710-48ca-9825-a657efc4016b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "section08_import_export_solution",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
