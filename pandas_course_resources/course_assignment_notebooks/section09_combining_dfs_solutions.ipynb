{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a9c0b25-2fa3-4d3a-b657-d1878a290843",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f106820-3a6c-4ce0-b3b4-bf60d64b6baf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment 1: pd.Concat\n",
    "\n",
    "Combine the 2014 and 2015 data you wrote out in the last section into a single dataframe. \n",
    "\n",
    "Then delete the transactions DataFrame (there is a handy base Python keyword for this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6693f2df-791c-4b1a-a241-0779fc99fff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code to read in transactions data if you need to re-create CSV/Excel files from section 8 \n",
    "# NOTE: You won't have the extra columns we created but it won't matter for this assignment\n",
    "\n",
    "# transactions = pd.read_csv(\"../retail/transactions.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Excel\n",
    "# with pd.ExcelWriter(\"DataForChandler.xlsx\") as writer:\n",
    "#     for year in range(2013, 2018):\n",
    "#         transactions.loc[transactions[\"date\"].dt.year == year].to_excel(\n",
    "#             writer, sheet_name=str(year)\n",
    "#         )\n",
    "        \n",
    "# CSV        \n",
    "# for year in range(2013, 2018):\n",
    "#     transactions.loc[transactions[\"date\"].dt.year == year].to_csv(\n",
    "#         f\"transactions_{year}.csv\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0220cdae-d010-43b8-a57d-f066b3e7e81f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CSV\n",
    "\n",
    "# Read in two csv files and concatenate them into a single DataFrame\n",
    "\n",
    "transactions = pd.concat(\n",
    "    (pd.read_csv(\"transactions_2014.csv\"), \n",
    "     pd.read_csv(\"transactions_2015.csv\")),\n",
    ").drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dac1129-c5f5-4e1c-8c72-82c7145b71d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Excel \n",
    "\n",
    "# Read in two Excel sheets and concatenate them into a single DataFrame\n",
    "\n",
    "transactions = pd.concat(\n",
    "    pd.read_excel(\"DataForChandler.xlsx\", sheet_name=[1, 2]),  #  specify sheets 1 and 2 to grab correct years\n",
    "    ignore_index=True  #  specify to create consecutive index across sheets\n",
    ").drop([\"Unnamed: 0\"], axis=1)  #  drop index col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f91fe4d1-8825-40ae-bacd-00bf572d780f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# inspect head of df\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95c2388f-ebda-4df4-8c25-e6d2a76e842e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# inspect tail of df\n",
    "\n",
    "transactions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d67b01b-c7fd-4fef-a6c1-ec0d3ae8965d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# delete DataFrame from memory\n",
    "\n",
    "del transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d3ff856-3feb-4064-835b-6d7ebc91c264",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment 2: Joins\n",
    "\n",
    "Can you join retail.csv with stores.csv? You'll need to read both files in.\n",
    "\n",
    "Once you have that, plot:\n",
    "* Total sales by city, \n",
    "* The sum of sales by “type” over time,\n",
    "* A stacked bar chart with average daily sales by type by month, with “type” as the “stacks”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d09096f2-fcd8-4395-adec-98b2291cc2f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retail = pd.read_csv(\"../retail/retail_2016_2017.csv\", parse_dates=[\"date\"])\n",
    "stores = pd.read_csv(\"../retail/stores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99e810cf-0977-4501-99e6-f47d247fa819",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ee6ea8d-da5b-4686-bd67-ea4647631e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "472595b4-2650-4eb9-8ffb-243b77192c90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Inner join stores to retail on 'store_nbr' column\n",
    "\n",
    "retail_stores = retail.merge(stores,\n",
    "                             how=\"inner\",\n",
    "                             left_on=\"store_nbr\",\n",
    "                             right_on=\"store_nbr\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d413b9b-ffdb-48d5-b517-0330782eb08f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Look at head of DataFrame to confirm Join as expected\n",
    "retail_stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5de40887-e49f-451d-ada5-539e1fdb5af0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Look at info of joined DataFrame\n",
    "\n",
    "retail_stores.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e53f71a3-2c56-43ab-a978-320c2fe6e48f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group joined DF by city, calculate sales by city, create bar plot from highest to lowest\n",
    "\n",
    "(retail_stores\n",
    " .groupby([\"city\"])\n",
    " .agg({\"sales\": \"sum\"})\n",
    " .sort_values(by=\"sales\", ascending=False\n",
    ").plot.bar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c5cec98-1dfc-489e-a559-f4ba97d159cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create pivot table with date in index and type as column, cells are sum sales for type/day\n",
    "# then create a line plot with increased figure size\n",
    "\n",
    "retail_stores.pivot_table(\n",
    "    index=[\"date\"], \n",
    "    columns=\"type\", \n",
    "    values=\"sales\", \n",
    "    aggfunc=\"sum\"\n",
    ").plot(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bd93e0c-1849-4794-9819-b94ff26363dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create pivot table with type in index and month as column, cells are sum sales for type/day\n",
    "# Note: You may have chosen row as month and type as column, that's fine too!\n",
    "\n",
    "retail_stores.pivot_table(\n",
    "    index=\"type\", \n",
    "    columns=retail_stores[\"date\"].dt.month, \n",
    "    values=\"sales\", \n",
    "    aggfunc=\"mean\"\n",
    ").T.plot.bar(stacked=True).legend(bbox_to_anchor=(1, 1)) # T, or transpose flips the DataFrame by its axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "daad6101-2d1f-4838-b4a4-65b1f7ff1976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delete DataFrames used in join\n",
    "\n",
    "del [retail, stores]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "section09_combining_dfs_solutions",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
